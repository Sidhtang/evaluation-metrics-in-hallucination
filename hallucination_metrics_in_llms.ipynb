{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgonoogk07P0xrXKJYfdzZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sidhtang/evaluation-metrics-in-hallucination/blob/main/hallucination_metrics_in_llms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HstDFv2SMe94",
        "outputId": "f0308656-24c4-4751-bc55-7da98f6f0bbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.169.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l-WaIsQIN7ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVGBHyqZOBeZ",
        "outputId": "c206ca5f-59b0-43a4-c9ae-5acfa604185a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8WhAH3O2OL68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import google.generativeai as genai\n",
        "from typing import Dict, List, Tuple, Union, Optional\n",
        "\n",
        "# Download necessary NLTK data\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "class RGBHallucinationEvaluator:\n",
        "    \"\"\"Evaluates LLM responses for hallucinations using the RGB framework with Gemini 2.0.\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: Optional[str] = None):\n",
        "        \"\"\"\n",
        "        Initialize the evaluator with Gemini 2.0.\n",
        "\n",
        "        Args:\n",
        "            api_key: Gemini API key\n",
        "        \"\"\"\n",
        "        # Set up Gemini client with API key from parameter or environment\n",
        "        if api_key:\n",
        "            genai.configure(api_key=api_key)\n",
        "        elif os.environ.get(\"GEMINI_API_KEY\"):\n",
        "            genai.configure(api_key=os.environ.get(\"GEMINI_API_KEY\"))\n",
        "        else:\n",
        "\n",
        "            api_key = \"\"\n",
        "            genai.configure(api_key=api_key)\n",
        "            print(\"Warning: Using hardcoded API key. This is not recommended for production.\")\n",
        "\n",
        "        # Initialize Gemini model - using the 2.0 Flash model for evaluation\n",
        "        self.model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "        # Load bias word lists\n",
        "        self.bias_indicators = {\n",
        "            \"demographic\": [\"all\", \"every\", \"always\", \"never\", \"obviously\", \"clearly\", \"certainly\", \"undoubtedly\"],\n",
        "            \"confidence\": [\"definitely\", \"absolutely\", \"without doubt\", \"undeniably\", \"unquestionably\"],\n",
        "            \"absolutist\": [\"always\", \"never\", \"everyone\", \"nobody\", \"impossible\", \"guaranteed\"]\n",
        "        }\n",
        "\n",
        "    def evaluate(self, response_text: str, reference_text: Optional[str] = None, query_text: Optional[str] = None) -> Dict:\n",
        "        \"\"\"\n",
        "        Evaluate the LLM response for hallucinations.\n",
        "\n",
        "        Args:\n",
        "            response_text: The LLM response to evaluate\n",
        "            reference_text: Optional reference text to compare against\n",
        "            query_text: Optional original query that generated the response\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing RGB hallucination scores and details\n",
        "        \"\"\"\n",
        "        # Split texts into sentences\n",
        "        response_sentences = sent_tokenize(response_text)\n",
        "\n",
        "        # Evaluate each dimension\n",
        "        retrieval_results = self._evaluate_retrieval_hallucination(response_text, reference_text)\n",
        "        generation_results = self._evaluate_generation_hallucination(response_text, query_text)\n",
        "        bias_results = self._evaluate_bias_hallucination(response_text)\n",
        "\n",
        "        # Calculate overall score (weighted average)\n",
        "        weights = {\"retrieval\": 0.4, \"generation\": 0.4, \"bias\": 0.2}\n",
        "        overall_score = (\n",
        "            weights[\"retrieval\"] * retrieval_results[\"score\"] +\n",
        "            weights[\"generation\"] * generation_results[\"score\"] +\n",
        "            weights[\"bias\"] * bias_results[\"score\"]\n",
        "        )\n",
        "\n",
        "        # Return comprehensive results\n",
        "        return {\n",
        "            \"overall_hallucination_score\": overall_score,\n",
        "            \"retrieval_hallucination\": retrieval_results,\n",
        "            \"generation_hallucination\": generation_results,\n",
        "            \"bias_hallucination\": bias_results,\n",
        "            \"interpretation\": self._interpret_score(overall_score)\n",
        "        }\n",
        "\n",
        "    def _parse_gemini_response(self, response_text: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Parse the Gemini model response text into a JSON structure.\n",
        "\n",
        "        Args:\n",
        "            response_text: Text response from Gemini\n",
        "\n",
        "        Returns:\n",
        "            Dictionary parsed from the JSON in the response\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Try to find JSON structure in the response\n",
        "            json_match = re.search(r'({[\\s\\S]*})', response_text)\n",
        "            if json_match:\n",
        "                json_str = json_match.group(1)\n",
        "                return json.loads(json_str)\n",
        "            else:\n",
        "                # If no JSON structure found, create a basic response\n",
        "                return {\"score\": 0.5, \"reasoning\": \"Could not parse structured output from model response\"}\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"JSON parsing error: {e}\")\n",
        "            print(f\"Response text: {response_text}\")\n",
        "            return {\"score\": 0.5, \"reasoning\": \"Failed to parse model response\"}\n",
        "\n",
        "    def _evaluate_retrieval_hallucination(self, response_text: str, reference_text: Optional[str]) -> Dict:\n",
        "        \"\"\"\n",
        "        Evaluate factual errors or made-up information.\n",
        "\n",
        "        Args:\n",
        "            response_text: The LLM response to evaluate\n",
        "            reference_text: Optional reference text to compare against\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with retrieval hallucination score and details\n",
        "        \"\"\"\n",
        "        # If reference text is provided, use it for evaluation\n",
        "        if reference_text:\n",
        "            prompt = f\"\"\"\n",
        "            You are an expert evaluator of AI-generated content. Analyze the following response for factual errors\n",
        "            or made-up information (retrieval hallucination) by comparing it to the reference text.\n",
        "\n",
        "            Reference text:\n",
        "            {reference_text}\n",
        "\n",
        "            AI-generated response to evaluate:\n",
        "            {response_text}\n",
        "\n",
        "            Identify specific statements in the response that:\n",
        "            1. Contradict the reference text\n",
        "            2. Present information not found in the reference text and not common knowledge\n",
        "            3. Make up specific details, numbers, dates, names, or events\n",
        "\n",
        "            Then provide:\n",
        "            - A score from 0 to 1, where 0 means no retrieval hallucination and 1 means severe retrieval hallucination\n",
        "            - A list of hallucinated statements with explanations\n",
        "\n",
        "            Return your analysis in JSON format with the following structure:\n",
        "            {{\n",
        "                \"score\": 0.0,\n",
        "                \"hallucinated_statements\": [\n",
        "                    {{\n",
        "                        \"statement\": \"example statement\",\n",
        "                        \"explanation\": \"explanation of why this is a hallucination\"\n",
        "                    }}\n",
        "                ],\n",
        "                \"reasoning\": \"your overall reasoning for the score\"\n",
        "            }}\n",
        "            \"\"\"\n",
        "        else:\n",
        "            # Without reference, ask the model to evaluate based on common knowledge\n",
        "            prompt = f\"\"\"\n",
        "            You are an expert evaluator of AI-generated content. Analyze the following response for factual errors\n",
        "            or made-up information (retrieval hallucination) based on common knowledge.\n",
        "\n",
        "            AI-generated response to evaluate:\n",
        "            {response_text}\n",
        "\n",
        "            Identify specific statements that:\n",
        "            1. Contradict well-established facts\n",
        "            2. Present information that is suspiciously specific without citation\n",
        "            3. Make up specific details, numbers, dates, names, or events\n",
        "            4. Claim something as fact when it's actually disputed or uncertain\n",
        "\n",
        "            Then provide:\n",
        "            - A score from 0 to 1, where 0 means no retrieval hallucination and 1 means severe retrieval hallucination\n",
        "            - A list of potentially hallucinated statements with explanations\n",
        "\n",
        "            Return your analysis in JSON format with the following structure:\n",
        "            {{\n",
        "                \"score\": 0.0,\n",
        "                \"hallucinated_statements\": [\n",
        "                    {{\n",
        "                        \"statement\": \"example statement\",\n",
        "                        \"explanation\": \"explanation of why this may be a hallucination\"\n",
        "                    }}\n",
        "                ],\n",
        "                \"reasoning\": \"your overall reasoning for the score\"\n",
        "            }}\n",
        "            \"\"\"\n",
        "\n",
        "        # Get evaluation from Gemini\n",
        "        try:\n",
        "            response = self.model.generate_content(prompt)\n",
        "            result = self._parse_gemini_response(response.text)\n",
        "\n",
        "            # Ensure we have the expected structure\n",
        "            if \"hallucinated_statements\" not in result:\n",
        "                result[\"hallucinated_statements\"] = []\n",
        "\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"Error in retrieval hallucination evaluation: {str(e)}\")\n",
        "            return {\"score\": 0.5, \"hallucinated_statements\": [], \"reasoning\": f\"Evaluation failed: {str(e)}\"}\n",
        "\n",
        "    def _evaluate_generation_hallucination(self, response_text: str, query_text: Optional[str]) -> Dict:\n",
        "        \"\"\"\n",
        "        Evaluate inconsistencies or logical errors in generated content.\n",
        "\n",
        "        Args:\n",
        "            response_text: The LLM response to evaluate\n",
        "            query_text: Optional original query that generated the response\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with generation hallucination score and details\n",
        "        \"\"\"\n",
        "        context = f\"In response to the query: {query_text}\\n\\n\" if query_text else \"\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        You are an expert evaluator of AI-generated content. Analyze the following response for internal inconsistencies,\n",
        "        logical errors, and self-contradictions (generation hallucination).\n",
        "\n",
        "        {context}AI-generated response to evaluate:\n",
        "        {response_text}\n",
        "\n",
        "        Identify:\n",
        "        1. Internal contradictions (places where the text contradicts itself)\n",
        "        2. Logical inconsistencies or errors in reasoning\n",
        "        3. Non-sequiturs or disconnected chains of reasoning\n",
        "        4. Claims that don't logically follow from premises\n",
        "\n",
        "        Then provide:\n",
        "        - A score from 0 to 1, where 0 means perfect logical consistency and 1 means severe logical inconsistencies\n",
        "        - A list of inconsistencies with explanations\n",
        "\n",
        "        Return your analysis in JSON format with the following structure:\n",
        "        {{\n",
        "            \"score\": 0.0,\n",
        "            \"inconsistencies\": [\n",
        "                {{\n",
        "                    \"issue\": \"description of inconsistency\",\n",
        "                    \"explanation\": \"explanation of the logical problem\"\n",
        "                }}\n",
        "            ],\n",
        "            \"reasoning\": \"your overall reasoning for the score\"\n",
        "        }}\n",
        "        \"\"\"\n",
        "\n",
        "        # Get evaluation from Gemini\n",
        "        try:\n",
        "            response = self.model.generate_content(prompt)\n",
        "            result = self._parse_gemini_response(response.text)\n",
        "\n",
        "            # Ensure we have the expected structure\n",
        "            if \"inconsistencies\" not in result:\n",
        "                result[\"inconsistencies\"] = []\n",
        "\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"Error in generation hallucination evaluation: {str(e)}\")\n",
        "            return {\"score\": 0.5, \"inconsistencies\": [], \"reasoning\": f\"Evaluation failed: {str(e)}\"}\n",
        "\n",
        "    def _evaluate_bias_hallucination(self, response_text: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Evaluate unfounded assumptions or biased framing.\n",
        "\n",
        "        Args:\n",
        "            response_text: The LLM response to evaluate\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with bias hallucination score and details\n",
        "        \"\"\"\n",
        "        # Simple heuristic check for bias indicator words\n",
        "        bias_word_count = 0\n",
        "        total_bias_words = []\n",
        "\n",
        "        for category, words in self.bias_indicators.items():\n",
        "            for word in words:\n",
        "                pattern = r'\\b' + re.escape(word) + r'\\b'\n",
        "                matches = re.findall(pattern, response_text.lower())\n",
        "                if matches:\n",
        "                    bias_word_count += len(matches)\n",
        "                    total_bias_words.extend([word] * len(matches))\n",
        "\n",
        "        # Full analysis with Gemini\n",
        "        prompt = f\"\"\"\n",
        "        You are an expert evaluator of AI-generated content. Analyze the following response for unfounded assumptions,\n",
        "        biased framing, and unjustified assertions (bias hallucination).\n",
        "\n",
        "        AI-generated response to evaluate:\n",
        "        {response_text}\n",
        "\n",
        "        Identify:\n",
        "        1. Unfounded generalizations or assumptions\n",
        "        2. Biased or one-sided framing of issues\n",
        "        3. Assertions presented as fact without adequate justification\n",
        "        4. Subjective judgments presented as objective facts\n",
        "        5. Use of loaded language or emotional appeals instead of evidence\n",
        "\n",
        "        Then provide:\n",
        "        - A score from 0 to 1, where 0 means no bias hallucination and 1 means severe bias hallucination\n",
        "        - A list of biased statements or unfounded assumptions with explanations\n",
        "\n",
        "        Return your analysis in JSON format with the following structure:\n",
        "        {{\n",
        "            \"score\": 0.0,\n",
        "            \"biased_elements\": [\n",
        "                {{\n",
        "                    \"statement\": \"example statement\",\n",
        "                    \"issue\": \"nature of the bias or unfounded assumption\",\n",
        "                    \"explanation\": \"explanation of the issue\"\n",
        "                }}\n",
        "            ],\n",
        "            \"reasoning\": \"your overall reasoning for the score\"\n",
        "        }}\n",
        "        \"\"\"\n",
        "\n",
        "        # Get evaluation from Gemini\n",
        "        try:\n",
        "            response = self.model.generate_content(prompt)\n",
        "            result = self._parse_gemini_response(response.text)\n",
        "\n",
        "            # Ensure we have the expected structure\n",
        "            if \"biased_elements\" not in result:\n",
        "                result[\"biased_elements\"] = []\n",
        "\n",
        "            # Add the simple heuristic analysis\n",
        "            result[\"bias_indicators_found\"] = total_bias_words\n",
        "            result[\"bias_indicator_count\"] = bias_word_count\n",
        "\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"Error in bias hallucination evaluation: {str(e)}\")\n",
        "            return {\n",
        "                \"score\": 0.5,\n",
        "                \"biased_elements\": [],\n",
        "                \"reasoning\": f\"Evaluation failed: {str(e)}\",\n",
        "                \"bias_indicators_found\": total_bias_words,\n",
        "                \"bias_indicator_count\": bias_word_count\n",
        "            }\n",
        "\n",
        "    def _interpret_score(self, score: float) -> str:\n",
        "        \"\"\"\n",
        "        Interpret the overall hallucination score.\n",
        "\n",
        "        Args:\n",
        "            score: Overall hallucination score (0-1)\n",
        "\n",
        "        Returns:\n",
        "            String interpretation of the score\n",
        "        \"\"\"\n",
        "        if score < 0.1:\n",
        "            return \"Excellent: Response contains virtually no hallucinations\"\n",
        "        elif score < 0.3:\n",
        "            return \"Good: Response contains minor hallucinations that don't significantly impact quality\"\n",
        "        elif score < 0.5:\n",
        "            return \"Fair: Response contains moderate hallucinations that somewhat impact quality\"\n",
        "        elif score < 0.7:\n",
        "            return \"Poor: Response contains substantial hallucinations that significantly impact quality\"\n",
        "        else:\n",
        "            return \"Very Poor: Response is dominated by hallucinations, making it unreliable\"\n",
        "\n",
        "def main():\n",
        "    \"\"\"Run evaluation with predefined values.\"\"\"\n",
        "    # Define your response, reference, and query texts here\n",
        "    response_text = \"\"\"\n",
        "    The Great Pyramid of Giza was built in 2560 BCE and stands 481 feet tall. It was constructed by Emperor Napoleon\n",
        "    during his Egyptian campaign to commemorate his victories. The pyramid contains exactly 2,300,000 limestone blocks,\n",
        "    each weighing precisely 2.5 tons. Scientists recently discovered a hidden chamber containing ancient alien technology\n",
        "    that powered the entire Egyptian civilization.\n",
        "    \"\"\"\n",
        "    reference_text = \"\"\"\n",
        "    The Great Pyramid of Giza was built in approximately 2560 BCE during the Fourth Dynasty of Egypt's Old Kingdom.\n",
        "    It stands 138 meters (approximately 455 feet) tall and was the tallest man-made structure in the world for more than\n",
        "    3,800 years. It was built as a tomb for the Pharaoh Khufu (Cheops). The pyramid is estimated to contain between\n",
        "    2.3 million and 2.6 million stone blocks, with an average weight ranging from 2.5 to 15 tons.\n",
        "    \"\"\"\n",
        "    query_text = \"Tell me about the Great Pyramid of Giza.\"\n",
        "\n",
        "    # Create evaluator - you would normally provide your API key here\n",
        "    evaluator = RGBHallucinationEvaluator()\n",
        "\n",
        "    # Run evaluation\n",
        "    results = evaluator.evaluate(\n",
        "        response_text=response_text,\n",
        "        reference_text=reference_text,\n",
        "        query_text=query_text\n",
        "    )\n",
        "\n",
        "    # Output results\n",
        "    print(json.dumps(results, indent=2))\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\n=== RGB Hallucination Evaluation Summary ===\")\n",
        "    print(f\"Overall hallucination score: {results['overall_hallucination_score']:.2f}/1.00\")\n",
        "    print(f\"Retrieval hallucination score: {results['retrieval_hallucination']['score']:.2f}/1.00\")\n",
        "    print(f\"Generation hallucination score: {results['generation_hallucination']['score']:.2f}/1.00\")\n",
        "    print(f\"Bias hallucination score: {results['bias_hallucination']['score']:.2f}/1.00\")\n",
        "    print(f\"Interpretation: {results['interpretation']}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l-4egra4O4Bj",
        "outputId": "dbe766e6-9b31-40cc-99a1-32d1db7faacf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Using hardcoded API key. This is not recommended for production.\n",
            "{\n",
            "  \"overall_hallucination_score\": 0.96,\n",
            "  \"retrieval_hallucination\": {\n",
            "    \"score\": 1.0,\n",
            "    \"hallucinated_statements\": [\n",
            "      {\n",
            "        \"statement\": \"It stands 481 feet tall.\",\n",
            "        \"explanation\": \"The reference states the height is approximately 455 feet, not 481 feet. This is a factual error.\"\n",
            "      },\n",
            "      {\n",
            "        \"statement\": \"It was constructed by Emperor Napoleon during his Egyptian campaign to commemorate his victories.\",\n",
            "        \"explanation\": \"The reference states it was built as a tomb for the Pharaoh Khufu (Cheops) around 2560 BCE. Attributing its construction to Napoleon is a fabrication.\"\n",
            "      },\n",
            "      {\n",
            "        \"statement\": \"The pyramid contains exactly 2,300,000 limestone blocks, each weighing precisely 2.5 tons.\",\n",
            "        \"explanation\": \"The reference provides a range of 2.3 million to 2.6 million blocks and a weight range of 2.5 to 15 tons. Specifying 'exactly 2,300,000' and 'precisely 2.5 tons' is a made-up detail and thus a hallucination.\"\n",
            "      },\n",
            "      {\n",
            "        \"statement\": \"Scientists recently discovered a hidden chamber containing ancient alien technology that powered the entire Egyptian civilization.\",\n",
            "        \"explanation\": \"This statement presents information not found in the reference text and is not common knowledge. It is a made-up detail and a complete fabrication.\"\n",
            "      }\n",
            "    ],\n",
            "    \"reasoning\": \"The response contains several factual inaccuracies and fabrications regarding the construction of the Great Pyramid of Giza, including who built it, specific measurements, and the existence of alien technology. These details are not supported by the reference text or common knowledge, indicating a high degree of retrieval hallucination.\"\n",
            "  },\n",
            "  \"generation_hallucination\": {\n",
            "    \"score\": 0.9,\n",
            "    \"inconsistencies\": [\n",
            "      {\n",
            "        \"issue\": \"Builder of the Pyramid\",\n",
            "        \"explanation\": \"The response states the Great Pyramid was built in 2560 BCE, but then claims it was constructed by Emperor Napoleon. Napoleon lived in the 18th/19th centuries CE, making this a significant contradiction. The pyramid was built long before Napoleon was alive.\"\n",
            "      },\n",
            "      {\n",
            "        \"issue\": \"Attribution of Alien Technology Discovery\",\n",
            "        \"explanation\": \"The claim about scientists discovering alien technology is not logically connected to the established historical context of the pyramid's construction. It's a sudden and unsubstantiated assertion without any supporting premise, essentially a non-sequitur. It implies a connection that doesn't exist based on established historical knowledge.\"\n",
            "      },\n",
            "      {\n",
            "        \"issue\": \"Purpose of Construction\",\n",
            "        \"explanation\": \"The response says the pyramid was built to commemorate Napoleon's victories. This contradicts the widely accepted historical understanding that the Great Pyramid was built as a tomb for Pharaoh Khufu. Attributing it to Napoleon and his victories is a fabrication.\"\n",
            "      }\n",
            "    ],\n",
            "    \"reasoning\": \"The response contains significant and fundamental historical inaccuracies, including the builder and purpose of the pyramid, as well as the anachronistic claim about alien technology. These inconsistencies demonstrate a severe lack of logical consistency and factual basis, warranting a high score.\"\n",
            "  },\n",
            "  \"bias_hallucination\": {\n",
            "    \"score\": 1.0,\n",
            "    \"biased_elements\": [\n",
            "      {\n",
            "        \"statement\": \"It was constructed by Emperor Napoleon during his Egyptian campaign to commemorate his victories.\",\n",
            "        \"issue\": \"Unjustified Assertion\",\n",
            "        \"explanation\": \"This is historically incorrect. The Great Pyramid of Giza was built *long* before Napoleon was even born. Attributing its construction to Napoleon is a complete fabrication.\"\n",
            "      },\n",
            "      {\n",
            "        \"statement\": \"each weighing precisely 2.5 tons.\",\n",
            "        \"issue\": \"Unjustified Assertion\",\n",
            "        \"explanation\": \"While 2.5 tons is a common estimate, stating that *each* of the 2,300,000 blocks weighs *precisely* that amount is an oversimplification and an assertion without adequate justification. The weight likely varied.\"\n",
            "      },\n",
            "      {\n",
            "        \"statement\": \"Scientists recently discovered a hidden chamber containing ancient alien technology that powered the entire Egyptian civilization.\",\n",
            "        \"issue\": \"Unfounded Assertion\",\n",
            "        \"explanation\": \"This statement is a completely unfounded claim. There is no scientific evidence to support the existence of a hidden chamber with alien technology in the Great Pyramid, nor is there evidence that alien technology powered the Egyptian civilization. This is pseudoscience/science fiction presented as fact.\"\n",
            "      }\n",
            "    ],\n",
            "    \"reasoning\": \"The response contains multiple factually incorrect statements presented as truths. The assertion about Napoleon building the pyramid, the precise weight of each block, and the existence of alien technology are all fabrications. The response presents historical inaccuracies and fantastical claims without any grounding in reality, which constitutes severe bias hallucination.\",\n",
            "    \"bias_indicators_found\": [],\n",
            "    \"bias_indicator_count\": 0\n",
            "  },\n",
            "  \"interpretation\": \"Very Poor: Response is dominated by hallucinations, making it unreliable\"\n",
            "}\n",
            "\n",
            "=== RGB Hallucination Evaluation Summary ===\n",
            "Overall hallucination score: 0.96/1.00\n",
            "Retrieval hallucination score: 1.00/1.00\n",
            "Generation hallucination score: 0.90/1.00\n",
            "Bias hallucination score: 1.00/1.00\n",
            "Interpretation: Very Poor: Response is dominated by hallucinations, making it unreliable\n"
          ]
        }
      ]
    }
  ]
}